{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memorywrap in /opt/conda/lib/python3.8/site-packages (1.0.0)\r\n",
      "Requirement already satisfied: torch>1.5 in /opt/conda/lib/python3.8/site-packages (from memorywrap) (1.9.0a0+2ecb2c7)\r\n",
      "Requirement already satisfied: entmax in /opt/conda/lib/python3.8/site-packages (from memorywrap) (1.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>1.5->memorywrap) (3.7.4.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install memorywrap\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from memorywrap import MemoryWrapLayer, BaselineMemory\n",
    "seed = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to add a Memory Wrap layer to a given architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from the definition of the starting model. For example here we have the implementation of MobileNet-v2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''expand + depthwise + pointwise'''\n",
    "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        planes = expansion * in_planes\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out\n",
    "    \n",
    "class MobileNetV2(nn.Module):\n",
    "    # (expansion, out_planes, num_blocks, stride)\n",
    "    cfg = [(1,  16, 1, 1),\n",
    "           (6,  24, 2, 1), \n",
    "           (6,  32, 3, 2),\n",
    "           (6,  64, 4, 2),\n",
    "           (6,  96, 3, 1),\n",
    "           (6, 160, 3, 2),\n",
    "           (6, 320, 1, 1)]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add the Memory Wrap to this architecture we have to:\n",
    "* replace the last layer with a Memory Wrap layer;\n",
    "* modify the forward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the last layer\n",
    "The first edit is straightforward. In this case we have to replace the line of code <br>\n",
    "```self.linear = nn.Linear(1280, num_classes)``` <br>\n",
    "with <br>\n",
    "```self.mw = MemoryWrapLayer(1280,num_classes)``` <br>\n",
    "where the parameters are the same: the first one is the number of dimension in input, and the second one is the output's dimension.\n",
    "If you want to use the baseline that uses only the memory to compute the output, please replace MemoryWrapLayer with BaselineMemory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify the forward function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second step, first of all, we have to remove the call to self.linear in the forward function, being removed from the code, and rename the forward function. For clearness we rename it in forward_encoder, highlighting the role of this function for our architecture. <br> Therefore, the forward function becomes:\n",
    "```python\n",
    "def forward_encoder(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        #here we removed the call to self.linear\n",
    "        \n",
    "        return out\n",
    "```\n",
    "\n",
    "And then we can make our new forward function that includes our new Memory Wrap layer.\n",
    "```python\n",
    "    def forward(self, x, ss, return_weights=False):\n",
    "\n",
    "        # inputs\n",
    "        out = self.forward_encoder(x)\n",
    "        out_ss = self.forward_encoder(ss)\n",
    "\n",
    "        # prediction\n",
    "        out_mw = self.mw(out,out_ss,return_weights)\n",
    "        return out_mw\n",
    "```\n",
    "\n",
    "What the forward function does is encoding both the input and the memory set and pass them to the Memory Wrap layer. The last argument of the Memory Wrap's call function is a boolean flag controlling the number of outputs returned. If the flag is True, then the layer returns both the output and the sparse attention weight associated to each memory sample; if the flag is False, then the layer return only the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging all the modification together we can create a new class called MemoryWrapMobileNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryWrapMobileNetV2(nn.Module):\n",
    "    # (expansion, out_planes, num_blocks, stride)\n",
    "    cfg = [(1,  16, 1, 1),\n",
    "           (6,  24, 2, 1),  # NOTE: change stride 2 -> 1 for CIFAR10\n",
    "           (6,  32, 3, 2),\n",
    "           (6,  64, 4, 2),\n",
    "           (6,  96, 3, 1),\n",
    "           (6, 160, 3, 2),\n",
    "           (6, 320, 1, 1)]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MemoryWrapMobileNetV2, self).__init__()\n",
    "        # NOTE: change conv1 stride 2 -> 1 for CIFAR10\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        \n",
    "        #replaced last layer\n",
    "        #self.linear = nn.Linear(1280, num_classes)\n",
    "        self.mw = MemoryWrapLayer(1280,num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward_encoder(self, x):\n",
    "\n",
    "        #input\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        # NOTE: change pooling kernel_size 7 -> 4 for CIFAR10\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, memory_set, return_weights=False):\n",
    "\n",
    "        #input\n",
    "        out = self.forward_encoder(x)\n",
    "        out_ms = self.forward_encoder(memory_set)\n",
    "\n",
    "        # prediction\n",
    "        out_mw = self.mw(out,out_ms,return_weights)\n",
    "        return out_mw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the SVHN dataset and randomly extract 2000 samples that will be our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG dataset\n",
    "len_dataset = 2000 # size training dataset\n",
    "data_dir = 'datasets/' #directory where dataset is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to datasets/train_32x32.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e419bac9696445129ba136a93dff49e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=182040794.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to datasets/test_32x32.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c561a8d40d48fdb28f21d7bc626efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=64275384.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In the training dataset there are 2000 samples.\n"
     ]
    }
   ],
   "source": [
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        normalize,\n",
    "])\n",
    "train_data = torchvision.datasets.SVHN(data_dir, split='train', download=True, transform=transforms)\n",
    "test_data =  torchvision.datasets.SVHN(data_dir, split='test', download=True, transform=transforms)\n",
    "train_dataset, _ = torch.utils.data.random_split(train_data,[len_dataset,len(train_data)-len_dataset], generator=torch.Generator().manual_seed(seed))\n",
    "print(\"In the training dataset there are {} samples.\".format(len(train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataloaders for training and testing. Note that both the loaders for the training set and for the memory set share the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "batch_size_train = 128\n",
    "samples_in_memory = 100\n",
    "batch_size_test = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=batch_size_train, shuffle=True, drop_last=True)\n",
    "mem_loader = torch.utils.data.DataLoader(train_dataset, batch_size=samples_in_memory, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=False,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code prepare two models for comparison: the standard MobileNet and the variant with Memory Wrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "num_epochs = 40\n",
    "dict_optim = {'lr' :1e-1, 'momentum':0.9, 'weight_decay':5e-4, 'nesterov':True}\n",
    "\n",
    "\n",
    "std_model = MobileNetV2(10)\n",
    "std_model = std_model.to(device)\n",
    "std_optimizer = torch.optim.SGD(std_model.parameters(),**dict_optim)\n",
    "std_scheduler = torch.optim.lr_scheduler.MultiStepLR(std_optimizer,  milestones=[20,30])\n",
    "\n",
    "mw_model = MemoryWrapMobileNetV2(10)\n",
    "mw_model = mw_model.to(device)\n",
    "mw_optimizer = torch.optim.SGD(mw_model.parameters(),**dict_optim)\n",
    "mw_scheduler = torch.optim.lr_scheduler.MultiStepLR(mw_optimizer,  milestones=[20,30])\n",
    "\n",
    "\n",
    "loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [(0%(2000)]\t\r"
     ]
    }
   ],
   "source": [
    "mw_model.train()\n",
    "std_model.train()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for batch_idx, (data, y) in enumerate(train_loader):\n",
    "\n",
    "        std_optimizer.zero_grad()\n",
    "        mw_optimizer.zero_grad()\n",
    "        \n",
    "        # input\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # here we randomly extract a new memory set for the given batch\n",
    "        memory_input, _ = next(iter(mem_loader))\n",
    "        memory_input = memory_input.to(device)\n",
    "        \n",
    "        # note that the memory model takes both the input and the memory set\n",
    "        mw_outputs  = mw_model(data,memory_input)\n",
    "        mw_loss = loss_criterion(mw_outputs, y)\n",
    "        \n",
    "        std_outputs  = std_model(data)\n",
    "        std_loss = loss_criterion(std_outputs, y)\n",
    "        \n",
    "        std_loss.backward()\n",
    "        mw_loss.backward()\n",
    "        \n",
    "        \n",
    "        std_optimizer.step()\n",
    "        mw_optimizer.step()\n",
    "        \n",
    "        #log stuff\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [({:.0f}%({})]\\t'.format(\n",
    "            epoch,\n",
    "            100. * batch_idx / len(train_loader), len(train_loader.dataset)),end='\\r')\n",
    "\n",
    "    std_scheduler.step()# increase scheduler step for each epoch\n",
    "    mw_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to evaluate our two models, comparing their accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_model.eval()\n",
    "mw_model.eval()\n",
    "std_correct = 0\n",
    "mw_correct = 0\n",
    "with torch.no_grad():\n",
    "    for _, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        memory, _ = next(iter(mem_loader))\n",
    "        memory = memory.to(device)\n",
    "\n",
    "        mw_outputs  = mw_model(data,memory_input)\n",
    "        mw_loss = loss_criterion(mw_outputs, y)\n",
    "        mw_pred = mw_outputs.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        std_outputs  = std_model(data)\n",
    "        std_loss = loss_criterion(std_outputs, y)\n",
    "        std_pred = std_outputs.data.max(1, keepdim=True)[1]\n",
    "\n",
    "        std_correct += std_pred.eq(target.data.view_as(std_pred)).sum().item()\n",
    "        mw_correct += mw_pred.eq(target.data.view_as(mw_pred)).sum().item()\n",
    "\n",
    "std_accuracy = 100.*(torch.true_divide(std_correct,len(test_loader.dataset))).item()\n",
    "mw_accuracy = 100.*(torch.true_divide(mw_correct,len(test_loader.dataset))).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard model correctly classify 70.24% of the images\n",
      "The model with Memory Wrap correctly classify 77.95% of the images\n"
     ]
    }
   ],
   "source": [
    "print(\"The standard model correctly classify {:.2f}% of the images\".format(std_accuracy))\n",
    "print(\"The model with Memory Wrap correctly classify {:.2f}% of the images\".format(mw_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
